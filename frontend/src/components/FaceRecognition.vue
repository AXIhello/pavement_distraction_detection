<template>
  <div class="face-camera">
    <h2>äººè„¸è¯†åˆ«</h2>
    <div class="mode-tabs">
      <button :class="{active: mode==='camera'}" @click="setMode('camera')">æ‘„åƒå¤´è¯†åˆ«</button>
      <button :class="{active: mode==='image'}" @click="setMode('image')">ä¸Šä¼ å›¾ç‰‡</button>
      <button :class="{active: mode==='video'}" @click="setMode('video')">ä¸Šä¼ è§†é¢‘</button>
    </div>

    <!-- æ‘„åƒå¤´ç”»é¢ -->
   <div class="video-container" v-if="mode==='camera' && !recognitionFinished" ref="videoContainer">
  <video ref="video" autoplay playsinline></video>
  <canvas ref="overlayCanvas" class="overlay-canvas"></canvas> <!-- ç”¨äºç”»æ¡† -->
</div>


    <!-- ä¸Šä¼ å›¾ç‰‡ -->
    <div v-if="mode==='image' && !recognitionFinished">
      <input type="file" accept="image/*" @change="onImageUpload" />
      <p class="tip">é€‰æ‹©ä¸€å¼ æœ¬åœ°å›¾ç‰‡è¿›è¡Œè¯†åˆ«</p>
    </div>

    <!-- ä¸Šä¼ è§†é¢‘ -->
    <div v-if="mode==='video' && !recognitionFinished">
      <input type="file" accept="video/*" @change="onVideoUpload" />
      <p class="tip">é€‰æ‹©ä¸€ä¸ªæœ¬åœ°è§†é¢‘ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æŠ½å¸§è¯†åˆ«</p>
    </div>

    <!-- è¿›åº¦æ¡ -->
    <div class="progress-bar" v-if="!recognitionFinished">
      <div class="progress-inner" :style="{ width: progress + '%' }"></div>
    </div>
    <p class="progress-status" v-if="!recognitionFinished">{{ progressStatus }}</p>

    <!-- è¯†åˆ«å‰ç•Œé¢ -->
    <div v-if="mode==='camera' && !recognitionFinished">
      <p class="tip">è¯·æ­£å¯¹æ‘„åƒå¤´ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«æ‚¨çš„äººè„¸</p>
      <button @click="startCamera">å¼€å¯æ‘„åƒå¤´è¯†åˆ«</button>
      <button style="margin-top: 12px;" @click="() => router.push('/first_page')">è¿”å›</button>
    </div>

    <!-- è¯†åˆ«å®Œæˆç•Œé¢ -->
    <div v-if="recognitionFinished">
      <p class="tip">è¯†åˆ«æˆåŠŸï¼Œæ¬¢è¿ï¼š<strong>{{ recognizedName }}</strong></p>
      <button @click="() => router.push('/first_page')">ä¸‹ä¸€æ­¥</button>
    </div>
  </div>
</template>

<script setup>
import { ref } from 'vue'
import { useRouter } from 'vue-router'
import { io } from 'socket.io-client'

const recognizedName = ref('')
const recognitionFinished = ref(false)
const router = useRouter()
const video = ref(null)

let socket = null
let streamInterval = null
let stream = null
let isWaitingForResult = false // æ˜¯å¦æ­£åœ¨ç­‰å¾…ç»“æœ
let frameCount = 0 // å½“å‰æ‰¹æ¬¡å·²å‘é€çš„å¸§æ•°
const FRAMES_PER_BATCH = 5 // æ¯æ‰¹æ¬¡å‘é€5å¸§
const BATCH_INTERVAL = 200 // æ‰¹æ¬¡å†…æ¯å¸§é—´éš”200ms
const WAIT_TIME = 1000 // ç­‰å¾…ç»“æœæ—¶é—´1000ms

const progress = ref(0) // è¿›åº¦æ¡ç™¾åˆ†æ¯”
const progressStatus = ref('è¯†åˆ«å‡†å¤‡ä¸­...') // çŠ¶æ€æç¤º
const mode = ref('camera') // å½“å‰æ¨¡å¼

//å¤„ç†å¼‚æ­¥é—®é¢˜
let requestId = 0
let latestReqId = 0 // åªæ¥å—è¿™ä¸€è½®çš„ç»“æœ

//äººè„¸æ ‡è¯†æ¡†
const overlayCanvas = ref(null)
const videoContainer = ref(null)

function drawFaceBoxes(bboxes) {
  const canvas = overlayCanvas.value
  const videoEl = video.value
  if (!canvas || !videoEl || videoEl.videoWidth === 0 || videoEl.videoHeight === 0) return

  // è®¾ç½® canvas å¤§å°ä¸è§†é¢‘åŒ¹é…
  canvas.width = videoEl.videoWidth
  canvas.height = videoEl.videoHeight

  const ctx = canvas.getContext('2d')
  ctx.clearRect(0, 0, canvas.width, canvas.height)
  ctx.lineWidth = 2
  ctx.strokeStyle = 'red'

  bboxes.forEach(bbox => {
    const scaleX = canvas.width / videoEl.videoWidth
    const scaleY = canvas.height / videoEl.videoHeight

    // å¦‚æœ bbox æ˜¯åŸå§‹åƒç´ åæ ‡ï¼ˆä¸ç¼©æ”¾ï¼‰ï¼Œç›´æ¥ç»˜åˆ¶
    const x = bbox.left
    const y = bbox.top
    const w = bbox.right - bbox.left
    const h = bbox.bottom - bbox.top

    ctx.strokeRect(x, y, w, h)
  })
}

function setMode(m) {
  stopAll()
  mode.value = m
  progress.value = 0
  progressStatus.value = 'è¯†åˆ«å‡†å¤‡ä¸­...'
  recognitionFinished.value = false
  recognizedName.value = ''
}

async function startCamera() {
  stopAll()
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video: true })
    video.value.srcObject = stream
    connectSocket()
    video.value.onloadedmetadata = () => {
      startImageStream()
    }
  } catch (err) {
    alert('æ— æ³•è®¿é—®æ‘„åƒå¤´ï¼š' + err.message)
  }
}

// å›¾ç‰‡è¯†åˆ« - ä½¿ç”¨APIæ¥å£
function onImageUpload(e) {
  stopAll()
  const file = e.target.files[0]
  if (!file) return

  const reader = new FileReader()
  reader.onload = async function(evt) {
    const base64Image = evt.target.result
    progress.value = 50
    progressStatus.value = 'è¯†åˆ«ä¸­...'

    try {
      const response = await fetch('http://127.0.0.1:8000/api/face/recognize', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image: base64Image })
      })

      const result = await response.json()
      progress.value = 100
      progressStatus.value = 'è¯†åˆ«å®Œæˆ'

      if (result.success && result.faces && result.faces.length > 0) {
        const face = result.faces[0]
        handleRecognitionResult(face)
      } else {
        progressStatus.value = result.message || 'è¯†åˆ«å¤±è´¥'
      }
    } catch (error) {
      console.error('APIè¯†åˆ«å¤±è´¥:', error)
      progressStatus.value = 'è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•'
    }
  }
  reader.readAsDataURL(file)
}

// è§†é¢‘è¯†åˆ« - ä½¿ç”¨Socket.IO
function onVideoUpload(e) {
  stopAll()
  const file = e.target.files[0]
  if (!file) return
  connectSocket()
  const url = URL.createObjectURL(file)
  const videoEl = document.createElement('video')
  videoEl.src = url
  videoEl.muted = true
  videoEl.playsInline = true
  videoEl.crossOrigin = 'anonymous'
  videoEl.currentTime = 0
  videoEl.play()
  videoEl.onloadedmetadata = () => {
    const duration = videoEl.duration
    const canvas = document.createElement('canvas')
    canvas.width = videoEl.videoWidth
    canvas.height = videoEl.videoHeight
    const ctx = canvas.getContext('2d')
    let currentTime = 0
    const interval = 0.2 // æ¯0.2ç§’æŠ½ä¸€å¸§
    let totalFrames = Math.floor(duration / interval)
    let sentFrames = 0
    function captureFrame() {
      videoEl.currentTime = currentTime
    }
    videoEl.onseeked = () => {
      ctx.drawImage(videoEl, 0, 0, canvas.width, canvas.height)
      const base64Image = canvas.toDataURL('image/jpeg')

      const currentReqId = requestId++
latestReqId = currentReqId // æ ‡è®°ä¸ºæœ€æ–°

socket.emit('face_recognition', {
  image: base64Image,
  req_id: currentReqId
})

      sentFrames++
      progress.value = Math.round((sentFrames / totalFrames) * 100)
      progressStatus.value = `è§†é¢‘è¯†åˆ«ä¸­... (${sentFrames}/${totalFrames})`
      currentTime += interval
      if (currentTime < duration) {
        setTimeout(captureFrame, 100)
      } else {
        progress.value = 100
        progressStatus.value = 'è§†é¢‘è¯†åˆ«å®Œæˆï¼Œç­‰å¾…ç»“æœ...'
        URL.revokeObjectURL(url)
      }
    }
    captureFrame()
  }
}

// ç»Ÿä¸€å¤„ç†è¯†åˆ«ç»“æœ
function handleRecognitionResult(face) {
  // DeepFake æ£€æµ‹å¼¹çª—ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
  if(face.name === 'deepfake') {
    alert(`âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ°DeepFakeäººè„¸ï¼`)
    stopAll()
    return
  }
  if (face.name === 'é™Œç”Ÿäºº') {
    alert('å‘Šè­¦ï¼šæ£€æµ‹åˆ°é™Œç”Ÿäººï¼')
    stopAll()
    router.push('/login')
    return
  }
   if (face.name === 'æœªçŸ¥äººå‘˜') {
    alert('äººè„¸æ•°æ®åº“ä¸­æ— æ•°æ®ï¼Œè¯·å‰å»å½•å…¥')
    stopAll()
    router.push('/face_register')
    return
  }
  recognizedName.value = face.name || ''
  recognitionFinished.value = true
  stopAll()
}

function sendRecognitionEndSignal() {
  if(socket && socket.connected) {
    socket.emit('face_recognition_end', { msg: 'recognition_finished' })
    console.log('å·²å‘é€è¯†åˆ«ç»“æŸä¿¡å·ç»™åç«¯')
  }
}

function connectSocket() {
  if (socket) {
    socket.disconnect()
    socket = null
  }
  socket = io('http://127.0.0.1:8000')
  socket.on('connect', () => {
    progress.value = 0
    progressStatus.value = 'è¯†åˆ«ä¸­...'
  })

 socket.on('face_bbox', (result) => {
  if (typeof result.req_id !== 'undefined' && result.req_id < latestReqId) {
    console.warn(`å¿½ç•¥è¿‡æœŸ bboxï¼šreq_id=${result.req_id} < ${latestReqId}`)
    return
  }

  if (result.success && result.bboxes && result.bboxes.length > 0) {
    drawFaceBoxes(result.bboxes)
  } else {
    // æ²¡æ£€æµ‹åˆ°äººè„¸ï¼Œæ¸…ç©ºæ¡†
    const ctx = overlayCanvas.value?.getContext('2d')
    if (ctx) ctx.clearRect(0, 0, overlayCanvas.value.width, overlayCanvas.value.height)
  }
})

socket.on('face_result', (result) => {
  if (typeof result.req_id !== 'undefined' && result.req_id < latestReqId) {
    console.warn(`å¿½ç•¥è¿‡æœŸè¯†åˆ«ç»“æœï¼šreq_id=${result.req_id} < ${latestReqId}`)
    return
  }

  isWaitingForResult = false
  progress.value = 100
  progressStatus.value = 'è¯†åˆ«å®Œæˆ'
  if (result.success) {
    console.log('ğŸ‰ è¯†åˆ«æˆåŠŸï¼Œå¤„ç†è¯†åˆ«ç»“æœ')
    const face = result.faces[0]
    handleRecognitionResult(face)
    sendRecognitionEndSignal()
  } else {
    console.warn('è¯†åˆ«å¤±è´¥:', result.message || 'æœªè¯†åˆ«åˆ°äººè„¸')
  }
})

  socket.on('disconnect', () => {
    stopAll()
  })
  socket.on('connect_error', (error) => {
    stopAll()
  })
}

function startImageStream() {
  streamInterval = setInterval(() => {
    if (!video.value || video.value.videoWidth === 0 || video.value.videoHeight === 0) return
    if (isWaitingForResult) return
    const canvas = document.createElement('canvas')
    canvas.width = video.value.videoWidth
    canvas.height = video.value.videoHeight
    const ctx = canvas.getContext('2d')
    ctx.drawImage(video.value, 0, 0, canvas.width, canvas.height)
    const base64Image = canvas.toDataURL('image/jpeg')
    socket.emit('face_recognition', { image: base64Image })
    frameCount++
    progress.value = Math.round((frameCount / FRAMES_PER_BATCH) * 100)
    progressStatus.value = 'è¯†åˆ«ä¸­...'
    if (frameCount >= FRAMES_PER_BATCH) {
      isWaitingForResult = true
      frameCount = 0
      progress.value = 100
      progressStatus.value = 'è¯†åˆ«ä¸­ï¼Œè¯·ç¨å€™...'
      setTimeout(() => {
        if (isWaitingForResult) {
          isWaitingForResult = false
          progress.value = 0
          progressStatus.value = 'è¯†åˆ«ä¸­...'
        }
      }, WAIT_TIME)
    }
  }, BATCH_INTERVAL)
}

function stopAll() {
  clearInterval(streamInterval)
  streamInterval = null
  if (stream) {
    stream.getTracks().forEach(track => track.stop())
    stream = null
  }
  if (socket) {
    sendRecognitionEndSignal()  
    socket.disconnect()
    socket = null
  }
  progress.value = 0
  progressStatus.value = 'è¯†åˆ«å‡†å¤‡ä¸­...'
  frameCount = 0
  isWaitingForResult = false
}
</script>

<style scoped>
.face-camera {
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 40px 20px;
  font-family: "Arial", sans-serif;
  background-color: #f9f9f9;
  border-radius: 16px;
  max-width: 480px;
  margin: 60px auto;
  box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);
}
.face-camera h2 {
  font-size: 28px;
  margin-bottom: 24px;
  color: #333;
}
.mode-tabs {
  display: flex;
  gap: 10px;
  margin-bottom: 20px;
}
.mode-tabs button {
  padding: 8px 18px;
  border: none;
  border-radius: 6px;
  background: #eee;
  color: #333;
  cursor: pointer;
  font-size: 15px;
  transition: background 0.2s;
}
.mode-tabs button.active {
  background: #d7c480;
  color: #fff;
}
.overlay-canvas {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none;
}
.video-container {
  position: relative; /* è®© canvas ç›¸å¯¹å®šä½ */
}

.video-container {
  width: 100%;
  aspect-ratio: 4/3;
  background-color: #000;
  border-radius: 12px;
  overflow: hidden;
  box-shadow: inset 0 0 10px rgba(0, 0, 0, 0.3);
}
.progress-bar {
  width: 100%;
  height: 10px;
  background: #eee;
  border-radius: 5px;
  margin: 16px 0 8px 0;
  overflow: hidden;
}
.progress-inner {
  height: 100%;
  background: #4caf50;
  transition: width 0.2s;
}
.progress-status {
  font-size: 14px;
  color: #888;
  text-align: center;
}
video {
  width: 100%;
  height: 100%;
  object-fit: cover;
}
button {
  margin-top: 20px;
  padding: 12px 24px;
  font-size: 16px;
  border: none;
  background-color: #d7c480;
  color: #fff;
  border-radius: 8px;
  cursor: pointer;
  transition: background-color 0.2s;
}
button:hover {
  background-color: #005fcc;
}
.tip {
  margin-top: 16px;
  font-size: 14px;
  color: #666;
}
</style>
